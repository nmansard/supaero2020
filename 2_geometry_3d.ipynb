{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct and inverse geometry of 3d robots\n",
    "This notebook introduces the kinematic tree of Pinocchio for a serial manipulator, explain how to compute the forward and inverse geometry (from configuration to end-effector placements, and inversely). The ideas are examplified with a simplified case-study taken from parallel robotics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: as for all the tutorials, a magic command %do_not_load is introduced to hide the solutions to some questions. Change it for %load if you want to see (and execute) the solution.\n"
     ]
    }
   ],
   "source": [
    "import magic_donotload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "We will need Pinocchio, Gepetto-Viewer, SciPy for the solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from pinocchio.robot_wrapper import RobotWrapper\n",
    "from pinocchio.utils import *\n",
    "import pinocchio as pio\n",
    "import eigenpy\n",
    "from scipy.optimize import fmin_bfgs\n",
    "eigenpy.switchToNumpyMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinematic tree in Pinocchio\n",
    "Let's now play with 3D robots. We will load the models from URDF files.\n",
    "\n",
    "*The robot UR5* is a low-cost manipulator robot with good performances. It is a fixed robot with one 6-DOF arms developed by the Danish company Universal Robot. All its 6 joints are revolute joints. Its configuration is in R^6 and is not subject to any constraint. The model of UR5 is described in a URDF file, with the visuals of the bodies of the robot being described as meshed (i.e. polygon soups) using the Collada format \".dae\". Both the URDF and the DAE files are available in the repository in the model directory. \n",
    "\n",
    "This robot model, as well as other models used in the notebooks, are installed from the apt paquet robotpkg-example-robot-data and stored in /opt/openrobots/share/example-robot-data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 9-14 tp2/simple_pick_and_place \n",
    "exampleRobotDataPath = '/opt/openrobots/share/example-robot-data/robots/'\n",
    "urdf = exampleRobotDataPath + 'ur_description/urdf/ur5_gripper.urdf'\n",
    "robot = RobotWrapper.BuildFromURDF( urdf, [ exampleRobotDataPath, ] )\n",
    "robot.initViewer(loadModel=True)\n",
    "NQ = robot.model.nq\n",
    "NV = robot.model.nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kinematic tree is represented by two C++ objects called Model (which contains the model constants: lengths, masses, names, etc) and Data (which contains the working memory used by the model algorithms). Both C\\++ objects are contained in a unique Python class. The first class is called RobotWrapper and is generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb joints = 7 (nq=6,nv=6)\n",
      "  Joint 0 universe: parent=0\n",
      "  Joint 1 shoulder_pan_joint: parent=0\n",
      "  Joint 2 shoulder_lift_joint: parent=1\n",
      "  Joint 3 elbow_joint: parent=2\n",
      "  Joint 4 wrist_1_joint: parent=3\n",
      "  Joint 5 wrist_2_joint: parent=4\n",
      "  Joint 6 wrist_3_joint: parent=5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(robot.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next steps, we are going to work with the RobotWrapper.\n",
    "\n",
    "Import the class RobotWrapper and create an instance of this class in the python terminal. At initialization, RobotWrapper will read the model description in the URDF file given as argument. In the following, we will use the model of the UR5 robot, available in the directory \"models\" of pinocchio (available in the homedir of the VBox). The code of the RobotWrapper class is in /opt/openrobots/lib/python2.7/site-packages/pinocchio/robot_wrapper.py . Do not hesitate to have a look at it and to take inspiration from the implementation of the class functions.\n",
    "\n",
    "Here are some import methods of the class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* robot.q0 contains a reference initial configuration of the robot (not a pretty good one for the UR-5).\n",
    "* robot.display(q) display the configuration q in the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.display(robot.q0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* robot.index('joint name') returns the index of the joint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.index(' wrist_3_joint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* robot.model.names is a container (~list) that contains all the joint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 universe\n",
      "1 shoulder_pan_joint\n",
      "2 shoulder_lift_joint\n",
      "3 elbow_joint\n",
      "4 wrist_1_joint\n",
      "5 wrist_2_joint\n",
      "6 wrist_3_joint\n"
     ]
    }
   ],
   "source": [
    "for i,n in enumerate(robot.model.names): print(i,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* robot.model.frames contains all the import frames attached to the robot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe attached to joint # 0\n",
      "root_joint attached to joint # 0\n",
      "world attached to joint # 0\n",
      "world_joint attached to joint # 0\n",
      "base_link attached to joint # 0\n",
      "base_link-base_fixed_joint attached to joint # 0\n",
      "base attached to joint # 0\n",
      "shoulder_pan_joint attached to joint # 1\n",
      "shoulder_link attached to joint # 1\n",
      "shoulder_lift_joint attached to joint # 2\n",
      "upper_arm_link attached to joint # 2\n",
      "elbow_joint attached to joint # 3\n",
      "forearm_link attached to joint # 3\n",
      "wrist_1_joint attached to joint # 4\n",
      "wrist_1_link attached to joint # 4\n",
      "wrist_2_joint attached to joint # 5\n",
      "wrist_2_link attached to joint # 5\n",
      "wrist_3_joint attached to joint # 6\n",
      "wrist_3_link attached to joint # 6\n",
      "ee_fixed_joint attached to joint # 6\n",
      "ee_link attached to joint # 6\n",
      "wrist_3_link-tool0_fixed_joint attached to joint # 6\n",
      "tool0 attached to joint # 6\n"
     ]
    }
   ],
   "source": [
    "for f in robot.model.frames: print(f.name,'attached to joint #',f.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* robot.placement(idx) and robot.framePlacement(idx) returns the placement (i.e. translation+rotation of the joint / frame in argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  R =\n",
       "          -1            0  3.58979e-09\n",
       "           0            1            0\n",
       "-3.58979e-09            0           -1\n",
       "  p =   0.81725   0.10915 -0.005491"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.placement(robot.q0,6) # Placement of the end effector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display simple geometries\n",
    "The robot is displayed in the viewer through robot.display(q). Other geometries (cubes, spheres, etc) can be displayed as well, see [the previous notebook](1_geometry_2d.ipynb#section_display_objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a red sphere\n",
    "gv = robot.viewer.gui\n",
    "ballID = \"world/ball\"\n",
    "rgbt = [1.0, 0.2, 0.2, 1.0]  # red-green-blue-transparency\n",
    "gv.addSphere(ballID, 0.05, rgbt)  # id, dim1, dim2, dim3, color\n",
    "# Place the ball at the position ( 0.5, 0.1, 0.2 )\n",
    "q_ball = [0.6, -0.1, 0.3, 1, 0, 0, 0]\n",
    "gv.applyConfiguration(ballID, q_ball)\n",
    "gv.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward (direct) geometry\n",
    "\n",
    "First, let's do some forward geometry, i.e. use Pinocchio to compute where is the end effector knowning the robot configuration.\n",
    "\n",
    "### Simple pick ...\n",
    "\n",
    "Say we have a target at position [.5,.1,.2] and we would like the robot to grasp it.\n",
    "First decide (by any way you want, e.g. trial and error) the configuration of the robot so that the end effector touches the ball.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = zero(NQ)  ### set the correct values here\n",
    "q[0] = 0.\n",
    "q[1] = 1.\n",
    "q[2] = 0.\n",
    "q[3] = 0.\n",
    "q[4] = 0.\n",
    "q[5] = 0.\n",
    "robot.display(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and simple place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the reference position you built, the end effector placement can be obtained by calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.placement(q,6).translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the translation part of the placement has been selected. The rotation is free.\n",
    "\n",
    "Now, choose any trajectory you want in the configuration space (it can be sinus-cosinus waves, polynomials, splines, straight lines). Make a for loop to display the robot at sampling positions along this trajectory. The function sleep can be used to slow down the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(.1) # in second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each instant of your loop, recompute the position of the ball and display it so that it always \"sticks\" to the robot end effector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.matrix([-.1,-1.2,1.7,.5,-.1,0]).T\n",
    "q_ball = [0.45, 0.2, 0.25, 1, 0, 0, 0]\n",
    "# yes, this configuration is not so precisely on the ball\n",
    "robot.display(q)\n",
    "ball = np.matrix(q_ball[:3]).T\n",
    "eff_to_ball = robot.placement(q,6).translation - ball\n",
    "v = np.matrix([.10, .20, .30, .20, .1, -.05]).T\n",
    "\n",
    "for i in range(1000):\n",
    "        q += v*1e-2\n",
    "        ball = robot.placement(q,6).translation + eff_to_ball\n",
    "        gv.applyConfiguration(ballID,tuple(ball.flat)+(1,0,0,0))\n",
    "        robot.display(q)\n",
    "        time.sleep(.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick and place in 3D\n",
    "\n",
    "Say now that the object is a rectangle and not a sphere. Pick the object at a reference position with the rotation that is imposed, so that the end effector is aligned with one of the faces of the rectangle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 16-24 tp2/simple_pick_and_place.py\n",
    "# Add a red box\n",
    "gv = robot.viewer.gui\n",
    "boxID = \"world/box\"\n",
    "rgbt = [1.0, 0.2, 0.2, 1.0]  # red-green-blue-transparency\n",
    "gv.addBox(boxID, 0.05, 0.1, 0.1, rgbt)  # id, dim1, dim2, dim3, color\n",
    "# Place the box at the position ( 0.5, 0.1, 0.2 )\n",
    "q_box = [0.5, 0.1, 0.2, 1, 0, 0, 0]\n",
    "gv.applyConfiguration(boxID, q_box)\n",
    "gv.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A configuration with the arm nicely attached to the box is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 31-38 tp2/simple_pick_and_place.py\n",
    "\n",
    "# Configuration for picking the box\n",
    "q = zero(NQ)\n",
    "q[0] = -0.375\n",
    "q[1] = -1.2\n",
    "q[2] = 1.71\n",
    "q[3] = -q[1] - q[2]\n",
    "q[4] = q[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo the same question as before, but now also choosing the orientation of the box. For that, at each robot configuration in your for-loop, compute the box placement wrt the world (let's denote it by oMbox) and display both the box and the robot configuration in the view. You can transform a SE3 object oMbox into a tuple [X,Y,Z,Quaternion] with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = robot.placement(q,6)\n",
    "pio.se3ToXYZQUATtuple(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%do_not_load -r 48-69 tp2/simple_pick_and_place.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse geometry\n",
    "\n",
    "We only yet computed the forward geometry, i.e. from configurations to end-effector placement. Let's to the inverse map not.\n",
    "\n",
    "### Inverse geometry in 3D\n",
    "\n",
    "Let's now first control the position (i.e. translation only) of the end effector of a manipulator robot to a given position. For this first part, we will use the fixed serial-chain robot model.\n",
    "\n",
    "Recall first that the position (3D) of the joint with index \"i=6\" at position \"q\" can be access by the following two lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.placement(q,6).translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the scipy solver [used in the previous notebook](1_geometry_2d.ipynb#section_optim), compute a configuration q where the end effector reaches p. For that, implement a cost function that takes a configuration as argument and returns the squared distance between the end effetor and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -r 35- tp2/invgeom3d.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse geometry in 6D\n",
    "6D means: translation and rotation. Change the previous cost function for a cost measuring the difference between the current placement root.placement(q,6) and a reference placement oMdes. \n",
    "For that, you can use the SE(3) log function to score the distance between two placements. The log returns a 6D velocity, represented by a class Motion, that must be transformed to a vector of R^6 from which you can take the norm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.log(pio.SE3.Identity()).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%do_not_load -r 35- tp2/invgeom6d.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next sections we will not need the quadruped any more: let's clean the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.deleteNode('world',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing in the quaternion space\n",
    "\n",
    "Let's now work with a floating robot: the quadruped ANYmal. This robot has 12 joints, but Q-space of size 19 (robot.model.nq) and Q-tangent space of size 18 (robot.model.nv). This is because with need 7D vector to encode the robot placement in space, which indeed to only 6 DOF.\n",
    "\n",
    "Run the following code. Can you explain what just happened? Then correct it to have a proper optimization of ANYmal configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp2/floating.py\n",
    "'''\n",
    "Stand-alone inverse geom in 3D.  Given a reference translation <target> ,\n",
    "it computes the configuration of the UR5 so that the end-effector position (3D)\n",
    "matches the target. This is done using BFGS solver. While iterating to compute\n",
    "the optimal configuration, the script also display the successive candidate\n",
    "solution, hence moving the robot from the initial guess configuaration to the\n",
    "reference target.\n",
    "'''\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pinocchio as pio\n",
    "from example_robot_data import loadANYmal\n",
    "from pinocchio.utils import *\n",
    "from scipy.optimize import fmin_bfgs\n",
    "import eigenpy\n",
    "eigenpy.switchToNumpyMatrix()\n",
    "\n",
    "# --- Load robot model\n",
    "robot = loadANYmal()\n",
    "robot.initViewer(loadModel=True)\n",
    "NQ = robot.model.nq\n",
    "NV = robot.model.nv\n",
    "robot.display(robot.q0)\n",
    "\n",
    "robot.feetIndexes = [ robot.model.getFrameId(frameName) for frameName in ['RH_FOOT','LH_FOOT','RF_FOOT','LF_FOOT' ] ]\n",
    "\n",
    "# --- Add box to represent target\n",
    "gv=robot.viewer.gui\n",
    "gv.addSphere(\"world/red\", .05, [1., .2, .2, .5])  # .1 is the radius\n",
    "gv.addSphere(\"world/blue\", .05, [.2, .2, 1., .5])  # .1 is the radius\n",
    "gv.addSphere(\"world/green\", .05, [.1, 1., .1, .5])  # .1 is the radius\n",
    "gv.addSphere(\"world/purple\", .05, [1., .2, 1., .5])  # .1 is the radius\n",
    "#gv.addSphere(\"world/white\", .05, [.9, .9, .9, .5])  # .1 is the radius\n",
    "\n",
    "gv.addSphere(\"world/red_des\", .05, [1., .2, .2, .95])  # .1 is the radius\n",
    "gv.addSphere(\"world/blue_des\", .05, [.2, .2, 1., .95])  # .1 is the radius\n",
    "gv.addSphere(\"world/green_des\", .05, [.1, 1., .1, .95])  # .1 is the radius\n",
    "gv.addSphere(\"world/purple_des\", .05, [1., .2, 1., .95])  # .1 is the radius\n",
    "#gv.addSphere(\"world/white_des\", .05, [.9, .9, .9, .95])  # .1 is the radius\n",
    "\n",
    "#\n",
    "# OPTIM 6D #########################################################\n",
    "#\n",
    "\n",
    "pdes = [\n",
    "    np.matrix(  [[-0.7, -0.2, 1.2]]).T,\n",
    "    np.matrix(  [[-0.3,  0.5,  0.8]]).T,\n",
    "    np.matrix(  [[0.3, 0.1, -0.1]]).T,\n",
    "    np.matrix(  [[0.9, 0.9, 0.5]]).T\n",
    "    ]\n",
    "for i in range(4): pdes[i][2]+=1\n",
    "colors = ['red','blue','green','purple']\n",
    "\n",
    "def cost(q):\n",
    "    '''Compute score from a configuration'''\n",
    "    q = np.matrix(q).T\n",
    "    cost = 0.\n",
    "    for i in range(4):\n",
    "        p_i = robot.framePlacement(q, robot.feetIndexes[i]).translation\n",
    "        cost += np.linalg.norm(p_i-pdes[i])**2\n",
    "    return cost\n",
    "\n",
    "def callback(q):\n",
    "    q = np.matrix(q).T\n",
    "    gv.applyConfiguration('world/box', pio.se3ToXYZQUATtuple(Mtarget))\n",
    "\n",
    "    for i in range(4):\n",
    "        p_i = robot.framePlacement(q, robot.feetIndexes[i])\n",
    "        gv.applyConfiguration('world/'+colors[i], pio.se3ToXYZQUATtuple(p_i))\n",
    "        gv.applyConfiguration('world/%s_des'%colors[i], tuple(pdes[i].flat)+(0,0,0,1))\n",
    "\n",
    "    robot.display(q)\n",
    "    time.sleep(1e-1)\n",
    "\n",
    "Mtarget = pio.SE3(rotate('x',3.14/4), np.matrix([0.5, 0.1, 0.2]).T)  # x,y,z\n",
    "qopt = fmin_bfgs(cost, robot.q0, callback=callback)\n",
    "qopt = np.matrix(qopt).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of parallel robots\n",
    "A parallel robot is composed of several kinematic chains (called the robot legs) that are all attached to the same end effector. This imposes strict constraints in the configuration space of the robot: a configuration is valide iff all the legs meets the same end-effector placement. We consider here only the geometry aspect of parallel robots (additionnally, some joints are not actuated, which causes additional problems).\n",
    "\n",
    "The kinematic structure of a paralel robot indeed induces loops in the joint connection graph. In Pinocchio, we can only represents (one of) the underlying kinematic tree. The loop constraints have to be handled separately. An example that loads 4 manipulator arms is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load tp2/example_parallel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Each leg i (for i=0,1,2,3) of the robot is loaded in the list robots[i]. The loop constraints are that the relative placement of every leg end-effector must stay the same that in the initial configuration given as example in the above file.\n",
    "\n",
    "Consider now that the orientation of the tool plate is given by the quaternion Quaternion(0.7,0.2,0.2,0.6), with the translation that you like (see [the notebook about rotations if you need more details](appendix1_quaternions.ipynb)). **Find using the above optimization routines the configuration of each robot leg so that the loop constraints are all met**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
